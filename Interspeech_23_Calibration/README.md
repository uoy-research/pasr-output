# Automatic speaker recognition with variation across vocal conditions

This markdown file details the workflow for the Interspeech submission *Automatic speaker recognition with variation across vocal conditions: a controlled experiment with implications for forensics* (include link if/when becomes available online)

## Test Data

Six male phoneticians
P0001  P0002 P0003 P0004 P0006 P0009

Which vocal conditions included:


(Explain why some excluded)


### Comps and scores

Include x-vectors and many-to-many comparison data (save final .csv from R)
Link to version of R code used to wrangle from VOCALISE


## Calibration Data

Include speaker numbers for DyViS speakers


### Comps and scores for Calibration Data

Include x-vectors and many-to-many comp data (save final .csv from R)


### Score-to-LR conversion

Include link to version of Matlab code used to do this

### Evaluation of performance 

Include link to version of Matlab code used to do this (could be collapsed into above section)

## Results

Include plot from article on git and include link here. Also link to version of R code used to generate final plot

Include code or plots which weren't included in final article (?)